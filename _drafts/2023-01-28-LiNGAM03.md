---
title: 03-LiNGAM algorithm
tags:
    - statistics
    - causalinference  
    - graphical
---

지난 글에서는 LiNGAM 알고리즘이 어떻게 돌아가는지 로직을 들여다보았다. 하지만 우리가 이렇게 얻은 $\widetilde{\mathbf{B}}$ 가 얼마나 믿을 수 있는지 알 방법이 있어야 하지 않을까? 이번에는 통계적 검정방법에 대해서 알아보자.

<!--more-->

## Statistical Tests for Pruning Edges

> The good news is that, in some caes, it is possible to detect violations of the model assumptions. In the following sections, we provide three statistical tests: i) testing significane of $b_{ij}$ for pruning edges; ii) examining an overall fit of the model assumptions including estimated structure and connection strengths to data; iii) comparing two nested models. The we propose a method for pruning edges of an estimated network using these statistical tests.

### Wald Test for Examining Significance of Edges

우선 Wald Test에 관해서는 <a href="https://junhyoung-chung.github.io/2023/01/28/LRT.html">이 포스트</a> 를 참고하자.

논문에서는 다음과 같은 가설 검정을 제안한다.

$$
H_0: \widetilde{w}_{ij}=0 \quad H_1: \widetilde{w}_{ij} \neq 0 
$$

or

$$
H_0: b_{ij}=0 \quad H_1: b_{ij} \neq 0 
$$

통계량으로는

$$
\frac{\widetilde{w}_{ij}^2}{avar(\widetilde{w}_{ij})}
$$

을 사용한다. $\widehat{\mathbf{B}}$가 $\widetilde{\mathbf{W}}$ 로부터 나오기 때문에 가설검정의 형태는 표현만 다르지 사실상 같다는 점을 유의하자. 그리고 이 통계량은 근사적으로 $\chi^2(1)$ 분포를 따른다.

### A Chi-Square Test for Evaluating the Overall Fit of the Estimated Model

> 여기가 살짝 이해가 잘 안 되는데,, 일단 쭉 리뷰해보자.

#### Moment Structures of Models

우선

$$
\mathbf{x}=(\mathbf{I}-\mathbf{B})^{-1}\mathbf{e}
$$

인 걸 다시 한번 상기하자. 편의상 $\mathbf{x}$의 평균은 0이라고 가정을 할 때 분산은 어떻게 될까? 평균이 0이라는 가정에서 살짝 의심스럽다면 우리가 ICA에서 자료를 centering하고 시작했다는 걸 기억하자.

$$
Var(\mathbf{x})=E(\mathbf{x}\mathbf{x}^T)=(\mathbf{I}-\mathbf{B})^{-1}\Sigma {(\mathbf{I}-\mathbf{B})^{-1}}^{T}
$$

그러고 나서 논문은 다음과 같은 $\sigma_2(\tau)$를 정의한다.

$$
\sigma_2(\tau)=\text{vec}^{+}\left\{ E(\mathbf{x}\mathbf{x}^T) \right\}
$$

여기서 $\text{vec}^+$라는 개념은 <a href="https://ko.wikipedia.org/wiki/벡터화">여기</a>를 참고하자. 그리고 논문에서 symmetry한 부분은 중복을 없앤다고 했다. 그니까 아마

$$
\sigma_2(\tau)=\begin{bmatrix}
E(x_1x_1) \\
E(x_2x_1) \\
\vdots \\
E(x_mx_1) \\
E(x_2x_2) \\
E(x_3x_2) \\
\vdots \\
E(x_mx_m)
\end{bmatrix}
$$

으로 $\frac{m(m+1)}{2} \times 1$ 차원의 열벡터가 될 것이다.

$\tau$를 어떻게 말하고 있냐면,

> the vector of statistics of disturbances and coefficients of $\mathbf{B}$ that uniquely determines the second-order moment structures of the model $\sigma_2(\tau)$

이게 무슨 뜻일까...? 추가적으로

> The parameter vector $\tau$ consists of free parameters of $\mathbf{B}$ and $E(e_i^2)$.

아마 식 (5)에서 $E(\mathbf{x}\mathbf{x}^T)$ 를 유일하게 결정지을 수 있는 coefficients들을 모아놓았다는 말인 듯 한데 아직 정확히 와닿지가 않는다.. 일단 넘어가자.

이제 $\mathbf{x}_1,\dots,\mathbf{x}_n$ 의 sample이 관찰된 경우를 생각하자. 그럼 우리는 $\sigma_2(\tau)$의 대용으로 다음과 같은 추정량을 찾을 것이다.

$$
m_2=\frac{1}{n}\sum_{j=1}^{n}\text{vec}^+(\mathbf{x}_j\mathbf{x}_j^T)
$$

여기서 $m_2 \overset{p}{\to} \sigma_2(\tau_0)$ 인걸 생각하면, $n$이 충분히 클 때 둘은 비슷한 값을 가지게 될 것이다. $\tau_0$은 true parameter을 말한다.

이 때, 논문에서는 다음과 같은 가설검정을 제안한다.

$$
H_0: E(m_2)=\sigma_2(\tau) \quad H_1: E(m_2) \neq \sigma_2(\tau) 
$$

이 떄 $\mathbf{V}$를 $m_2$의 공분산 행렬, $\widehat{\mathbf{V}}$를 $m_2$의 표본공분산 행렬로 정의한다.

그리고 $\mathbf{J}=\partial\sigma_2(\tau)/\partial\tau^T$로 정의할 때 다음과 같은 통계량을 생각하자.

$$
F(\hat{\tau})=\left\{ m_2-\sigma_2(\hat{\tau}) \right\}^T\widehat{\mathbf{M}}\left\{ m_2-\sigma_2(\hat{\tau}) \right\}
$$

where

$$
\widehat{\mathbf{M}} = \widehat{\mathbf{V}}^{-1}-\widehat{\mathbf{V}}^{-1}\widehat{\mathbf{J}}(\widehat{\mathbf{J}}^T\widehat{\mathbf{V}}^{-1}\widehat{\mathbf{J}})^{-1}\widehat{\mathbf{J}}^T\widehat{\mathbf{V}}^{-1}
$$

$$
\widehat{\mathbf{J}}=\frac{\partial{\sigma_2(\tau)}}{\partial{\tau^T}} \bigg|_{\tau=\hat{\tau}}
$$

으아 모르겠다.. 

하튼 이때 $T_1=n \times F(\hat{\tau})$는 귀무가설 하에서 근사적으로 자유도가 $u-\nu$ 인 카이제곱분포를 따르는데, $u$는 $m_2$의 차원, $\nu$는 $\tau$의 차원을 말하는 듯 하다.

하나하나 무슨 말을 하는지는 대충 알겠는데, 이게 정확히 왜 그런지는 모르겠다. 

$$
T_2 = \frac{T_1}{1+F(\hat{\tau})}
$$

가 더 카이제곱분포에 흡사하다는 것이 Yuan and Bentler(1997) 논문에서 밝혀졌다고 한다. 그래서 이 논문에서는 $T_2$를 검정통계량으로 사용하고 있다.

#### A Difference Chi-Square Test for Model Comparison of Nested Models




## Reference

* <a href="https://www.jmlr.org/papers/volume7/shimizu06a/shimizu06a.pdf">A Linear Non-Gaussian Acyclic Model for Causal Discovery</a>

* <a href="https://ko.wikipedia.org/wiki/치환행렬">치환행렬(Permutation Matrix)</a>

* <a href="https://gazelle-and-cs.tistory.com/29">할당 문제 & 헝가리안 알고리즘 (Assignment Problem & Hungarian Algorithm)</a>